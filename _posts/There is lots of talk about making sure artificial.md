---
layout: post
title: "Transparency in AI"
tags: [Artificial Intelligence]
---

There is lots of talk about making sure artificial intelligence is transparent


There are some ways we can do this that would be great

We could make a decision tree of whether to give parole




But for some things, this will hinder us, and it is not necesarry


Sometimes it will be desireable, but truly not feasible


For image recognition, we can form eigenimages, but that's only a suggestion



What kind of a reduction in performance are we OK with? 95% when unexplained, but when I restrict myself to transparent models, only 90%? Is that worth it. It depends on the situation. Maybe transparency is so important for parole.

I would push against this in another way? How transparent are the current methods? If you ask a judge, he'll say something. Someone will always say SOMETHING (like the experiments were peoples arms' are immobile and they "explain" why they used their other arm).
It's important to be clear-eyed about the current state of things.
But he will never say, it's because my blood sugar was low and I wasn't feeling good, although that's more likely to be the true reason.




There's no doubt there will be calls for transparency. The first crash will usher in such a call. But each call has to be looked at carefully. Perhaps we can have a transparent algorithm making the final call, but it's relying on nontransparent algorithm's below. Maybe the transparent says it went 80 mph because that's what the sign said, but below it was a nontransparent algorithm that saw the 30 mph sign and reported that it said 80. It could tell you which pixels were most important in that decision, but it can't really tell you why it saw what it did. (Back to my earlier point, take a look at this dress - is it blue and black or some other color combination. Now, the tricky part, tell me why. The "why" is you saw it and that's how it looks to you).

Reading text on signs probably won't be a problem, but there will be more complicated visual tasks.



Does it really matter if your movie recommendation engine can't explain how it got it's results? Surely not, but this is not to downplay the reality of the situation - sometimes there will be times when we want to know what an AI algorithm is thinking and cannot get that information



